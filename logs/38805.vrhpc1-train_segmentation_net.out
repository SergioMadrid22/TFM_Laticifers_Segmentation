/data/smadper@alumno.upv.es/TFM/env/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
2025-07-16 01:08:45 INFO Starting training with configuration: {'model': {'name': 'unet++', 'alias': 'unet++_densenet121', 'encoder_name': 'densenet121', 'encoder_weights': 'imagenet', 'in_channels': 1, 'classes': 1, 'activation': 'sigmoid', 'dropout': 0.2}, 'dataset': {'root': '/data/smadper@alumno.upv.es/TFM/datasets/laticifers', 'image_size': [512, 512], 'patch_size': [512, 512], 'stride': [256, 256], 'num_patches': 20, 'dataset_csv': 'laticifer_dataset_index.csv', 'num_workers': 8, 'positive_ratio': 0.8, 'fg_threshold': 0.04, 'dist_transform': True, 'feature_dirs': {'enhanced': '/data/smadper@alumno.upv.es/TFM/datasets/laticifers/enhanced_images', 'mask': '/data/smadper@alumno.upv.es/TFM/datasets/laticifers/masks', 'distance': '/data/smadper@alumno.upv.es/TFM/datasets/laticifers/distance_maps_pt'}}, 'train': {'batch_size': 8, 'num_epochs': 50, 'learning_rate': 0.001, 'accumulation_steps': 1, 'save_dir': '/data/smadper@alumno.upv.es/TFM/checkpoints', 'log_interval': 1, 'patience': 5, 'experiment_name': 'unet++_positive_sampling_drop_bce_dice', 'timestamp': '20250716_010845'}, 'test': {'batch_size': 1, 'save_dir': '/data/smadper@alumno.upv.es/TFM/results'}, 'loss': {'name': 'bce', 'cldice_alpha': 0.1, 'use_topographic': False, 'combine_with': 'dice', 'weights': {'main': 0.5, 'combined': 0.5}, 'topo': {'alpha': 2.0, 'beta': 1.0}}}
2025-07-16 01:08:45 INFO Experiment name: unet++_positive_sampling_drop_bce_dice
2025-07-16 01:08:45 INFO Loading model unet++ with settings {'name': 'unet++', 'alias': 'unet++_densenet121', 'encoder_name': 'densenet121', 'encoder_weights': 'imagenet', 'in_channels': 1, 'classes': 1, 'activation': 'sigmoid', 'dropout': 0.2}
2025-07-16 01:10:17 INFO Epoch 001 | Train Loss: 0.4634 | Val Loss: 0.3862 | Dice: 0.4405 | clDice: 0.5093 |IoU: 0.2829 | LR: 0.001000
2025-07-16 01:11:46 INFO Epoch 002 | Train Loss: 0.3871 | Val Loss: 0.3588 | Dice: 0.4654 | clDice: 0.5084 |IoU: 0.3035 | LR: 0.001000
2025-07-16 01:13:14 INFO Epoch 003 | Train Loss: 0.3770 | Val Loss: 0.3569 | Dice: 0.4731 | clDice: 0.4968 |IoU: 0.3102 | LR: 0.001000
2025-07-16 01:14:42 INFO Epoch 004 | Train Loss: 0.3722 | Val Loss: 0.3595 | Dice: 0.4579 | clDice: 0.5075 |IoU: 0.2973 | LR: 0.001000
2025-07-16 01:16:10 INFO Epoch 005 | Train Loss: 0.3646 | Val Loss: 0.3510 | Dice: 0.4696 | clDice: 0.4984 |IoU: 0.3073 | LR: 0.001000
2025-07-16 01:17:38 INFO Epoch 006 | Train Loss: 0.3659 | Val Loss: 0.3572 | Dice: 0.4693 | clDice: 0.4953 |IoU: 0.3069 | LR: 0.001000
2025-07-16 01:19:07 INFO Epoch 007 | Train Loss: 0.3591 | Val Loss: 0.3463 | Dice: 0.4829 | clDice: 0.5206 |IoU: 0.3187 | LR: 0.001000
2025-07-16 01:20:34 INFO Epoch 008 | Train Loss: 0.3572 | Val Loss: 0.3480 | Dice: 0.4780 | clDice: 0.5100 |IoU: 0.3145 | LR: 0.001000
2025-07-16 01:22:02 INFO Epoch 009 | Train Loss: 0.3529 | Val Loss: 0.3461 | Dice: 0.4766 | clDice: 0.5040 |IoU: 0.3131 | LR: 0.001000
2025-07-16 01:23:29 INFO Epoch 010 | Train Loss: 0.3502 | Val Loss: 0.3471 | Dice: 0.4686 | clDice: 0.4881 |IoU: 0.3064 | LR: 0.001000
2025-07-16 01:24:57 INFO Epoch 011 | Train Loss: 0.3474 | Val Loss: 0.3480 | Dice: 0.4707 | clDice: 0.4957 |IoU: 0.3085 | LR: 0.001000
2025-07-16 01:26:24 INFO Epoch 012 | Train Loss: 0.3461 | Val Loss: 0.3542 | Dice: 0.4739 | clDice: 0.5062 |IoU: 0.3108 | LR: 0.001000
2025-07-16 01:27:51 INFO Epoch 013 | Train Loss: 0.3428 | Val Loss: 0.3641 | Dice: 0.4461 | clDice: 0.4561 |IoU: 0.2873 | LR: 0.001000
2025-07-16 01:29:19 INFO Early stopping at epoch 14 | Best Dice: 0.4829 at epoch 9
2025-07-16 01:29:59 INFO Test Loss: 0.3461 | Dice: 0.4766 | IoU: 0.3131 | clDice: 0.5040
