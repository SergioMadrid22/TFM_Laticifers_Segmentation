/data/smadper@alumno.upv.es/TFM/env/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
2025-07-16 01:23:00 INFO Starting training with configuration: {'model': {'name': 'unet++', 'alias': 'unet++_se_resnext50_32x4d', 'encoder_name': 'se_resnext50_32x4d', 'encoder_weights': 'imagenet', 'in_channels': 1, 'classes': 1, 'activation': 'sigmoid', 'dropout': 0.2}, 'dataset': {'root': '/data/smadper@alumno.upv.es/TFM/datasets/laticifers', 'image_size': [512, 512], 'patch_size': [512, 512], 'stride': [256, 256], 'num_patches': 20, 'dataset_csv': 'laticifer_dataset_index.csv', 'num_workers': 8, 'positive_ratio': 0.8, 'fg_threshold': 0.04, 'dist_transform': True, 'feature_dirs': {'enhanced': '/data/smadper@alumno.upv.es/TFM/datasets/laticifers/enhanced_images', 'mask': '/data/smadper@alumno.upv.es/TFM/datasets/laticifers/masks', 'distance': '/data/smadper@alumno.upv.es/TFM/datasets/laticifers/distance_maps_pt'}}, 'train': {'batch_size': 8, 'num_epochs': 50, 'learning_rate': 0.001, 'accumulation_steps': 1, 'save_dir': '/data/smadper@alumno.upv.es/TFM/checkpoints', 'log_interval': 1, 'patience': 5, 'experiment_name': 'unet++_positive_sampling_drop_bce_dice_seresnext50', 'timestamp': '20250716_012300'}, 'test': {'batch_size': 1, 'save_dir': '/data/smadper@alumno.upv.es/TFM/results'}, 'loss': {'name': 'bce', 'cldice_alpha': 0.1, 'use_topographic': False, 'combine_with': 'dice', 'weights': {'main': 0.5, 'combined': 0.5}, 'topo': {'alpha': 2.0, 'beta': 1.0}}}
2025-07-16 01:23:00 INFO Experiment name: unet++_positive_sampling_drop_bce_dice_seresnext50
2025-07-16 01:23:00 INFO Loading model unet++ with settings {'name': 'unet++', 'alias': 'unet++_se_resnext50_32x4d', 'encoder_name': 'se_resnext50_32x4d', 'encoder_weights': 'imagenet', 'in_channels': 1, 'classes': 1, 'activation': 'sigmoid', 'dropout': 0.2}
Downloading: "http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth" to /data/smadper@alumno.upv.es/.cache/torch/hub/checkpoints/se_resnext50_32x4d-a260b3a4.pth
  0%|          | 0.00/105M [00:00<?, ?B/s]  0%|          | 256k/105M [00:00<00:50, 2.17MB/s]  3%|▎         | 3.12M/105M [00:00<00:06, 16.7MB/s]  6%|▋         | 6.62M/105M [00:00<00:04, 24.4MB/s] 10%|▉         | 10.2M/105M [00:00<00:03, 28.6MB/s] 13%|█▎        | 13.9M/105M [00:00<00:03, 31.0MB/s] 17%|█▋        | 17.5M/105M [00:00<00:02, 32.4MB/s] 20%|██        | 21.2M/105M [00:00<00:02, 33.5MB/s] 24%|██▎       | 25.0M/105M [00:00<00:02, 34.3MB/s] 27%|██▋       | 28.8M/105M [00:00<00:02, 34.9MB/s] 31%|███       | 32.6M/105M [00:01<00:02, 35.7MB/s] 35%|███▍      | 36.6M/105M [00:01<00:01, 36.6MB/s] 38%|███▊      | 40.5M/105M [00:01<00:01, 37.1MB/s] 42%|████▏     | 44.5M/105M [00:01<00:01, 37.7MB/s] 46%|████▌     | 48.5M/105M [00:01<00:01, 38.6MB/s] 50%|████▉     | 52.6M/105M [00:01<00:01, 39.0MB/s] 54%|█████▍    | 56.8M/105M [00:01<00:01, 39.3MB/s] 58%|█████▊    | 60.9M/105M [00:01<00:01, 40.0MB/s] 62%|██████▏   | 65.0M/105M [00:01<00:01, 40.4MB/s] 66%|██████▌   | 69.1M/105M [00:02<00:00, 40.6MB/s] 70%|██████▉   | 73.4M/105M [00:02<00:00, 41.4MB/s] 73%|███████▎  | 77.4M/105M [00:02<00:00, 41.4MB/s] 77%|███████▋  | 81.4M/105M [00:02<00:00, 40.7MB/s] 81%|████████  | 85.5M/105M [00:02<00:00, 40.8MB/s] 85%|████████▌ | 89.9M/105M [00:02<00:00, 41.6MB/s] 89%|████████▉ | 94.1M/105M [00:02<00:00, 42.4MB/s] 94%|█████████▎| 98.6M/105M [00:02<00:00, 42.5MB/s] 98%|█████████▊| 103M/105M [00:02<00:00, 43.0MB/s] 100%|██████████| 105M/105M [00:02<00:00, 37.5MB/s]
2025-07-16 01:24:22 INFO Epoch 001 | Train Loss: 0.5857 | Val Loss: 0.5424 | Dice: 0.3804 | clDice: 0.3627 |IoU: 0.2354 | LR: 0.001000
2025-07-16 01:25:38 INFO Epoch 002 | Train Loss: 0.4066 | Val Loss: 0.3705 | Dice: 0.4617 | clDice: 0.4834 |IoU: 0.3003 | LR: 0.001000
2025-07-16 01:26:55 INFO Epoch 003 | Train Loss: 0.3827 | Val Loss: 0.3597 | Dice: 0.4633 | clDice: 0.4753 |IoU: 0.3019 | LR: 0.001000
2025-07-16 01:28:11 INFO Epoch 004 | Train Loss: 0.3752 | Val Loss: 0.3621 | Dice: 0.4719 | clDice: 0.5125 |IoU: 0.3091 | LR: 0.001000
2025-07-16 01:29:30 INFO Epoch 005 | Train Loss: 0.3677 | Val Loss: 0.3550 | Dice: 0.4702 | clDice: 0.4898 |IoU: 0.3076 | LR: 0.001000
2025-07-16 01:30:47 INFO Epoch 006 | Train Loss: 0.3643 | Val Loss: 0.3488 | Dice: 0.4706 | clDice: 0.4743 |IoU: 0.3081 | LR: 0.001000
2025-07-16 01:32:02 INFO Epoch 007 | Train Loss: 0.3659 | Val Loss: 0.3509 | Dice: 0.4754 | clDice: 0.4919 |IoU: 0.3122 | LR: 0.001000
2025-07-16 01:33:18 INFO Epoch 008 | Train Loss: 0.3572 | Val Loss: 0.3513 | Dice: 0.4642 | clDice: 0.4793 |IoU: 0.3026 | LR: 0.001000
2025-07-16 01:34:34 INFO Epoch 009 | Train Loss: 0.3594 | Val Loss: 0.3461 | Dice: 0.4777 | clDice: 0.4892 |IoU: 0.3143 | LR: 0.001000
2025-07-16 01:35:50 INFO Epoch 010 | Train Loss: 0.3506 | Val Loss: 0.3512 | Dice: 0.4665 | clDice: 0.5102 |IoU: 0.3048 | LR: 0.001000
2025-07-16 01:37:06 INFO Epoch 011 | Train Loss: 0.3525 | Val Loss: 0.3495 | Dice: 0.4691 | clDice: 0.4866 |IoU: 0.3065 | LR: 0.001000
2025-07-16 01:38:20 INFO Epoch 012 | Train Loss: 0.3480 | Val Loss: 0.3475 | Dice: 0.4674 | clDice: 0.4911 |IoU: 0.3054 | LR: 0.001000
2025-07-16 01:39:35 INFO Epoch 013 | Train Loss: 0.3442 | Val Loss: 0.3468 | Dice: 0.4758 | clDice: 0.4924 |IoU: 0.3124 | LR: 0.001000
2025-07-16 01:40:50 INFO Early stopping at epoch 14 | Best Dice: 0.4777 at epoch 9
2025-07-16 01:41:17 INFO Test Loss: 0.3461 | Dice: 0.4777 | IoU: 0.3143 | clDice: 0.4892
