2025-07-11 04:18:26 INFO Starting training with configuration: {'model': {'name': 'unet', 'alias': 'unet_densenet121', 'encoder_name': 'densenet121', 'encoder_weights': 'imagenet', 'in_channels': 1, 'classes': 1, 'activation': 'sigmoid', 'dropout': 0.0}, 'dataset': {'root': '/data/smadper@alumno.upv.es/TFM/datasets/laticifers', 'image_size': [512, 512], 'patch_size': [512, 512], 'stride': [256, 256], 'num_patches': 40, 'dataset_csv': 'laticifer_dataset_index.csv', 'num_workers': 8}, 'train': {'batch_size': 16, 'num_epochs': 50, 'learning_rate': 0.001, 'accumulation_steps': 1, 'save_dir': '/data/smadper@alumno.upv.es/TFM/checkpoints', 'log_interval': 1, 'patience': 10, 'experiment_name': 'unet_tversky_clahe', 'timestamp': '20250711_041826'}, 'test': {'batch_size': 1, 'save_dir': '/data/smadper@alumno.upv.es/TFM/results'}, 'loss': {'name': 'bce', 'cldice_alpha': 0.3, 'use_topographic': False, 'combine_with': 'dice', 'weights': {'main': 1.0, 'combined': 0.5}, 'topo': {'alpha': 2.0, 'beta': 1.0}}}
2025-07-11 04:18:26 INFO Experiment name: unet_tversky_clahe
2025-07-11 04:18:26 INFO Loading model unet with settings {'name': 'unet', 'alias': 'unet_densenet121', 'encoder_name': 'densenet121', 'encoder_weights': 'imagenet', 'in_channels': 1, 'classes': 1, 'activation': 'sigmoid', 'dropout': 0.0}
2025-07-11 04:19:15 INFO Epoch 001 | Train Loss: 0.5896 | Val Loss: 0.4791 | Dice: 0.3374 | IoU: 0.2034 | LR: 0.001000
2025-07-11 04:20:03 INFO Epoch 002 | Train Loss: 0.4670 | Val Loss: 0.4265 | Dice: 0.4346 | IoU: 0.2782 | LR: 0.001000
2025-07-11 04:20:52 INFO Epoch 003 | Train Loss: 0.4509 | Val Loss: 0.4255 | Dice: 0.4387 | IoU: 0.2812 | LR: 0.001000
2025-07-11 04:21:40 INFO Epoch 004 | Train Loss: 0.4432 | Val Loss: 0.4080 | Dice: 0.4605 | IoU: 0.2995 | LR: 0.001000
2025-07-11 04:22:28 INFO Epoch 005 | Train Loss: 0.4332 | Val Loss: 0.4052 | Dice: 0.4797 | IoU: 0.3162 | LR: 0.001000
2025-07-11 04:23:17 INFO Epoch 006 | Train Loss: 0.4303 | Val Loss: 0.4016 | Dice: 0.4748 | IoU: 0.3119 | LR: 0.001000
2025-07-11 04:24:04 INFO Epoch 007 | Train Loss: 0.4287 | Val Loss: 0.4041 | Dice: 0.4686 | IoU: 0.3063 | LR: 0.001000
2025-07-11 04:24:53 INFO Epoch 008 | Train Loss: 0.4284 | Val Loss: 0.4091 | Dice: 0.4588 | IoU: 0.2981 | LR: 0.001000
2025-07-11 04:25:40 INFO Epoch 009 | Train Loss: 0.4250 | Val Loss: 0.4124 | Dice: 0.4499 | IoU: 0.2906 | LR: 0.001000
2025-07-11 04:26:30 INFO Epoch 010 | Train Loss: 0.4205 | Val Loss: 0.4129 | Dice: 0.4580 | IoU: 0.2974 | LR: 0.001000
2025-07-11 04:27:18 INFO Epoch 011 | Train Loss: 0.4217 | Val Loss: 0.4018 | Dice: 0.4788 | IoU: 0.3152 | LR: 0.001000
2025-07-11 04:28:07 INFO Epoch 012 | Train Loss: 0.4174 | Val Loss: 0.3995 | Dice: 0.4783 | IoU: 0.3148 | LR: 0.001000
2025-07-11 04:28:55 INFO Epoch 013 | Train Loss: 0.4160 | Val Loss: 0.4126 | Dice: 0.4512 | IoU: 0.2916 | LR: 0.001000
2025-07-11 04:29:42 INFO Epoch 014 | Train Loss: 0.4202 | Val Loss: 0.4135 | Dice: 0.4542 | IoU: 0.2943 | LR: 0.001000
2025-07-11 04:30:30 INFO Epoch 015 | Train Loss: 0.4088 | Val Loss: 0.4010 | Dice: 0.4788 | IoU: 0.3153 | LR: 0.001000
2025-07-11 04:31:18 INFO Epoch 016 | Train Loss: 0.4092 | Val Loss: 0.4045 | Dice: 0.4574 | IoU: 0.2971 | LR: 0.001000
2025-07-11 04:32:06 INFO Epoch 017 | Train Loss: 0.4151 | Val Loss: 0.4074 | Dice: 0.4675 | IoU: 0.3054 | LR: 0.001000
2025-07-11 04:32:54 INFO Epoch 018 | Train Loss: 0.4040 | Val Loss: 0.4047 | Dice: 0.4635 | IoU: 0.3023 | LR: 0.001000
2025-07-11 04:33:41 INFO Epoch 019 | Train Loss: 0.3985 | Val Loss: 0.4129 | Dice: 0.4585 | IoU: 0.2977 | LR: 0.001000
2025-07-11 04:34:28 INFO Epoch 020 | Train Loss: 0.4002 | Val Loss: 0.4264 | Dice: 0.4291 | IoU: 0.2735 | LR: 0.001000
2025-07-11 04:35:16 INFO Epoch 021 | Train Loss: 0.3976 | Val Loss: 0.4091 | Dice: 0.4518 | IoU: 0.2923 | LR: 0.001000
2025-07-11 04:36:04 INFO Early stopping at epoch 22 | Best Dice: 0.4797 at epoch 12
2025-07-11 04:36:19 INFO Test Loss: 0.3995 | Dice: 0.4783 | IoU: 0.3148
